---
permalink: /Neural N/
tags: 
  - Python Projects
layout: tags
categories:
  - Python
---

# Artificial Neural networks on python

In this exercise we simulate the Artificial Neural Networks (ANN) in class, this is an easy example and it is applied in Python. The computing procedure was done in Google Collaborate with the *TPU* configuration with the 'some power' mode. In this last setting, we used **gatito**, according to Google, this setting is a little more slowly than **Korgi** and with an extra of accuracy.


```python
import pandas as pd
import numpy as np
import tensorflow

ny = pd.read_csv('ny.csv', sep=';')
```
For this purpose we made a binomial variable (with values 0 and 1), with this new variable we intent to simulate the probability of been taken by the user, it is 0 - for not taken- and 1 if it chosen, reflecting that the service is taken. 

|    |Uber  |Lyft  |
|----|------|------|
|Size|192606|153084|
|in %|0.4994|0.4979|

```python
df = pd.DataFrame(np.random.randint(0,2, size=(693071, 1)), columns=list('H'))
ny1 = pd.concat([ny, df], axis=1, sort =True)

ny1.to_csv(index=False)
ny1.to_csv (r'C:\Users\magda\Desktop\MADM\Statistics\Proyect\ny1.csv', index = None, header=True) 
```
In that way, we run this simulation with `Tensorflow 2`. The reproduction was made for each firm, Uber and Lyft.
To reduce the length of the code, we decided to import the datasets from the previous exercises. 

Below, the code written is for the case of *Lyft*.

### Tensorflow 

```python
dataset = pd.read_csv('lyft.csv',sep=';')
dataset.head()

dataset=dataset.drop(columns=['hora', 'latitude', 'longitude','cab_type'])
```

#### The artificial neural networks code

From the original database we decided to delete the following variables: *hora, latitude, longitude and cab_type*, we think this set of variables are already characterized by some other variables considered in the simulation.  

```python
X = dataset.iloc[:, 3:41].values
y = dataset.iloc[:, 41].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)
```

Finally, the number considered are 38 variables, to made simple the exercise we use three hidden layers for the ANN.

```python
import keras
from keras.models import Sequential
from keras.layers import Dense
```
```python
classifier = Sequential()
classifier.add(Dense(units = 40, kernel_initializer = "random_uniform", bias_initializer='zeros', activation = "relu", 
                     input_dim = 38))

classifier.add(Dense(units = 40, kernel_initializer=("random_uniform"),  bias_initializer='zeros',  activation = "relu"))
classifier.add(Dense(units = 20, kernel_initializer = "TruncatedNormal", bias_initializer='zeros', activation = "relu"))
classifier.add(Dense(units = 10, kernel_initializer = "random_uniform",  bias_initializer='zeros', activation = "sigmoid"))

classifier.add(Dense(units = 1, kernel_initializer = "uniform", bias_initializer='zeros' ,activation = "sigmoid"))

classifier.compile(optimizer = "adam", loss = "binary_crossentropy", metrics = ["accuracy"])
classifier.fit(X_train, y_train, batch_size = 10 , epochs= 100)
```
Finally, the accuracy rate after 100 epochs:

|        |Uber  |Lyft  |
|--------|------|------|
|Accuracy|0.5192|0.5123|

After 100 epochs we found that the final accuracy figures are very similar, but Uber reaches a bit higher than Lyft, we think and this could be true due that Uber has a 25% more of presence of 'ones' in the elaborated variable.

### Predicting the results with the testing set

```python
y_pred  = classifier.predict(X_test)
y_pred = (y_pred>0.5)
```
### Constructing the Confusion Matrix

```r
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
```

After the replication, we compute the Confusion Matrix for both firms.


**Confusion Matrix for Uber**

|         |Taken    |Not taken|
|---------|---------|---------|
|Taken    |  41473  |  6897   |
|Not taken|  41015  |  7031   |


**Confusion Matrix for Lyft**

|         |Taken   |Not taken|
|---------|--------|---------|
|Taken    | 36290  |  1864   |
|Not taken| 36772  |  1926   |


Concluding and after the simulation, we can believe that both firms have the same probability of been taken for a ride, however, we think that the prediction could be better defined only considering the most relevant sources with more influence for each firm. Undoubtedly this just could be considered as a gentle introduction to Artificial Neural Networks in Python.


This is the end of part 7.




